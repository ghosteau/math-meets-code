# Math Meets Code -- A Mathematical Computing Project

A while back, I wrote a couple Python files pertaining to how to solve certain calculus problems using the `SymPy` library (which I directly utilize here), and as the projects grew in volume I found it more and more necessary to create one large repository/class that can deal with all of the techniques I have utilized in a more efficient manner.

This will be a "living repository" in effect, like many projects, so expect updates as time goes on. The files are not too large in terms of code currently -- most of the workload was largely converting the style of programming. On my older projects I took a utility approach to the problems, but as someone who recognized how hard this was going to sustain over time, I made the switch to an object-oriented paradigm. I believe this will accomodate the user experience more and compliment the `SymPy` library a bit more effectively.

I will do my best to keep an update log here for any updates, and explain the more confusing concepts along with those update logs. Hopefully this can be both a mathematical learning experience and a coding experience for everyone involved!

Some of the potential next concepts: washer & shell methods, ratio testing for series, optimization, related rates, polar coordinates & cartesian coordinate relationships (such as conversion and integration), LaPlace transforms, Taylor's series, partial differentiation, and more!

*Note: I am going to presume you have a basic calculus background with concepts such as derivatives/tangent lines and basic integration. I will try to update my explanations as I learn more about each concept.*

*Note 2: I am also branching outside of calculus and Python as a language. Expect some stuff in C++ and potentially Rust and/or Java.*
_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
**Newton's Method (Calculus on Code):**
How it works: Newton's method is iterative, so it was pretty natural how you could make this into a loop. What Newton's method actually does is takes an initial guess that you can choose, plugs it into your current function (we will use f(x)), and then divides it by f'(x) -- your derivative of the function. You simply subtract that from your guess, and then you will repeat this process, just using your brand new output value from the process above. I highly recommend checking out the formula if you are still confused, as it is technically an approximation technique, and not necessarily empirical (albeit, you can get VERY close to finding roots with lots of iterations). I recommend trying it yourself and seeing by inputting your own functions, and seeing how precise the guesses are in comparison to Desmos!
_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
**Linearization (Calculus on Code):**
Built off of some of the functions I used for my Newton's Method application, I decided to make another calculus application that performs linearization using derivatives and finding tangent lines. The general formula for linearization is f(a) + f'(a)(x - a), which turns into a function called L(x), and therefore prepares it for linearization. Why do we do this process? Originally, it was a concept used to approximate very complex or weird values, such as the square root of 1.99, or 3.99 cubed. Understandably, doing this with a real function would be quite difficult, but using derivatives and tangents simplifies complex functions into basic linear functions, therefore allowing us to find very close answers to the real value with much less work.

With the modern marvel of computers, this may not necessarily be an issue, but I figured writing a program that could show a tangent line instantaneously would be pretty neat, and be a cool little study that we can think of using calculus. Additionally, this is still a pretty useful concept especially when dealing with very complex functions, and in particular when you just need a rough answer for a weird value of a function.
_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
**Determinants with LaPlace Expansion (Linear Algebra Stuff):**
LaPlace Expansion is a really cool process we can use to evaluate determinants of matrices. I decided to write an algorithm in C++ that does exactly this, with some good comment explanations for anyone who is really interested. LaPlace expansion is, at its core, just a method of finding a cofactor, multiplying it by the determinant of its respective minor, and then taking the summation of these products (after this is calculated for the whole matrix... not just one row/column). The method itself is a little bit conceptually complex compared to the calculus stuff I have mentioned in the past, so I highly recommend looking at my comments; I will also publish a LaTeX document with some other cool facts about determinants and LaPlace Expansion. 

My last note for this algorithm is that it runs in the order of n! time complexity, meaning the runtime is, for lack of better terms, terrible. This should be treated as a toy example and a mind exercise moreover and not necessarily as something practical. Perhaps the next update could be a new, more computationally efficient technique though?
_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
**Gaussian Integral Simulation:**
This program was super easy especially compared to the others, as it isn't even really an algorithm, it's basically just a while loop with some markdown. The Gaussian integral is a fascinating integral that actually does not have a general anti-derivative! However, this didn't stop people from investigating the integral using definite integration. There are plenty of super cool ways of proving that the area under the Gaussian function is equal to the square root of pi, and I highly reccomend looking at some of them if you are more interested in... less ad hoc ways of observing this (unlike what I did here). My next goal would be to maybe go through some of these proofs through code, although this is admittedly on the backburner. Regardless, I hope you learn a thing or two from this quick little notebook I wrote up!
_________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________
Small Update 1: I added a `factorialRun` static function that can calculate the factorial of a number, notated as "n!" where n is any whole number. All this means is, suppose you have 4!, the result would be 4 * 3 * 2 * 1. It is merely a descending multiplication function. Do note that 0! = 1, and there are some ridiculous ways to prove this--but the easiest way to think about it is just that if you have zero permutations of something, that is technically and logically a permutation.
